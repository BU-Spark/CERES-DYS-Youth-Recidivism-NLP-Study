{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"Case Management Note_20200113.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "import re\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'our', 'have', 'themselves', \"shouldn't\", 'ain', 'd', \"that'll\", 'your', 'its', 'on', 'too', 'himself', \"it's\", 'itself', \"couldn't\", ',', \"weren't\", 'mightn', 'yourselves', 'during', 'she', 'aren', 'did', 'are', 'not', 'don', 'because', 't', 'how', 'most', 'what', \"haven't\", '?', 'or', 'very', 'why', 'under', 'only', 'can', 'weren', 'doing', 'more', 'after', 'other', 'into', 'needn', 'these', 'while', 'and', 'they', 'so', 'than', 'herself', 'couldn', 'doesn', 'up', 'if', 'that', 'each', 'from', 'by', 's', 'below', 'having', 'to', 'few', 'you', 'll', 'this', 'he', 'here', 'do', 'his', 'where', 'in', 'wasn', 'off', 'for', \"mightn't\", 'it', 'same', 'shan', 'an', \"wasn't\", 'with', 'ourselves', 'yourself', '(', 're', 'won', 'has', 'being', \"you'd\", 'the', 'o', 'him', 'above', 'will', 'now', \"you're\", 'hers', 'against', \"hasn't\", '.', 'ours', 've', 'wouldn', 'which', 'should', 'over', 'when', \"don't\", 'between', 'at', 'there', \"should've\", \"didn't\", 'out', 'we', 'i', 'both', 'does', 'some', 'them', 'those', \"won't\", 'any', 'was', 'no', \"shan't\", 'their', \"wouldn't\", 'theirs', \"she's\", ')', 'of', 'whom', \"doesn't\", 'through', \"isn't\", 'y', 'shouldn', 'who', 'is', 'a', 'all', 'nor', '!', 'm', 'own', \"needn't\", \"you'll\", \"aren't\", 'her', 'ma', 'isn', \"mustn't\", 'such', 'yours', 'but', 'further', 'been', 'mustn', 'down', 'just', 'then', 'be', 'had', 'hadn', 'myself', 'until', 'were', 'once', 'before', \"you've\", 'hasn', 'my', 'as', 'again', 'didn', \"hadn't\", 'am', 'haven', 'me', 'about'}\n"
     ]
    }
   ],
   "source": [
    "addlist=['.',',','!','?','(',')']\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for x in addlist:\n",
    "    stop_words.add(x)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(x):\n",
    "    out=[]\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    word_tokens=nltk.word_tokenize(x)\n",
    "#    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "#    for i in word_tokens:\n",
    "#         if i not in stop_words:\n",
    "#             lemmatized_word=lemmatize(i, allowed_tags=re.compile('(NN|JJ|RB)'))\n",
    "#             if lemmatized_word:\n",
    "#                     out += [lemmatized_word[0].split(b'/')[0].decode('utf-8')]\n",
    "#         else:\n",
    "#             continue\n",
    "#    word_tokens=[lemmatizer.lemmatize(x) for x in word_tokens]\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "    return filtered_sentence\n",
    "\n",
    "df['TOKEN']=df['COMMENTS'].apply(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MID</th>\n",
       "      <th>DATE_OF_NOTE</th>\n",
       "      <th>ADMIN_ENTRY</th>\n",
       "      <th>CONTACT_TYPE</th>\n",
       "      <th>CONTACT_CONNECTION</th>\n",
       "      <th>HOW_WAS_CONTACT_MADE</th>\n",
       "      <th>WHO_WAS_CONTACTED</th>\n",
       "      <th>WHY</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>COMMENTS_CLOB</th>\n",
       "      <th>...</th>\n",
       "      <th>STAFF_WHO_PH_OTH</th>\n",
       "      <th>STAFF_WHO_PH_EXT</th>\n",
       "      <th>STAFF_WHO_PH_EXT_OTH</th>\n",
       "      <th>STAFF_WHO_PH_INT</th>\n",
       "      <th>STAFF_WHO_PH_INT_OTH</th>\n",
       "      <th>STAFF_NOTES</th>\n",
       "      <th>STAFF_REC</th>\n",
       "      <th>CMN_COMMENTS</th>\n",
       "      <th>CMN_STAFFING_TYPE</th>\n",
       "      <th>TOKEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500554</td>\n",
       "      <td>09-JUN-15</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic Communications</td>\n",
       "      <td>Contact Made</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>Client</td>\n",
       "      <td>Behavior Management, Check-in, Health Services...</td>\n",
       "      <td>CW spoke to Angel today and explained that CW ...</td>\n",
       "      <td>CW spoke to Angel today and explained that CW ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CW spoke to Angel today and explained that CW ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cw, spoke, angel, today, explained, cw, ran, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500554</td>\n",
       "      <td>18-JUN-15</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic Communications</td>\n",
       "      <td>Contact Made</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>Client, Internal Collateral</td>\n",
       "      <td>Behavior Management</td>\n",
       "      <td>CW spoke to clinician Katlyn today who reports...</td>\n",
       "      <td>CW spoke to clinician Katlyn today who reports...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CW spoke to clinician Katlyn today who reports...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cw, spoke, clinician, katlyn, today, reports,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500554</td>\n",
       "      <td>11-MAY-15</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic Communications</td>\n",
       "      <td>Contact Made</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>Internal Collateral</td>\n",
       "      <td>Behavior Management, Check-in</td>\n",
       "      <td>CW spoke to Laura today and asked how Angel wa...</td>\n",
       "      <td>CW spoke to Laura today and asked how Angel wa...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CW spoke to Laura today and asked how Angel wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cw, spoke, laura, today, asked, angel, since,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500554</td>\n",
       "      <td>07-MAY-15</td>\n",
       "      <td>No</td>\n",
       "      <td>Program visit</td>\n",
       "      <td>Contact Made</td>\n",
       "      <td>Face-to-face</td>\n",
       "      <td>Client, Internal Collateral</td>\n",
       "      <td>Behavior Management, Check-in, Educational/Voc...</td>\n",
       "      <td>CW met with Angel and Laura today for Angel's ...</td>\n",
       "      <td>CW met with Angel and Laura today for Angel's ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CW met with Angel and Laura today for Angel's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cw, met, angel, laura, today, angel, 's, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500554</td>\n",
       "      <td>13-MAY-15</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic Communications</td>\n",
       "      <td>Contact Made</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>Client</td>\n",
       "      <td>Behavior Management, Check-in, Educational/Voc...</td>\n",
       "      <td>CW spoke to Angel today and he reports he is a...</td>\n",
       "      <td>CW spoke to Angel today and he reports he is a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CW spoke to Angel today and he reports he is a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cw, spoke, angel, today, reports, almost, don...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MID DATE_OF_NOTE ADMIN_ENTRY               CONTACT_TYPE  \\\n",
       "0  500554    09-JUN-15          No  Electronic Communications   \n",
       "1  500554    18-JUN-15          No  Electronic Communications   \n",
       "2  500554    11-MAY-15          No  Electronic Communications   \n",
       "3  500554    07-MAY-15          No              Program visit   \n",
       "4  500554    13-MAY-15          No  Electronic Communications   \n",
       "\n",
       "  CONTACT_CONNECTION HOW_WAS_CONTACT_MADE            WHO_WAS_CONTACTED  \\\n",
       "0       Contact Made            Telephone                       Client   \n",
       "1       Contact Made            Telephone  Client, Internal Collateral   \n",
       "2       Contact Made            Telephone          Internal Collateral   \n",
       "3       Contact Made         Face-to-face  Client, Internal Collateral   \n",
       "4       Contact Made            Telephone                       Client   \n",
       "\n",
       "                                                 WHY  \\\n",
       "0  Behavior Management, Check-in, Health Services...   \n",
       "1                                Behavior Management   \n",
       "2                      Behavior Management, Check-in   \n",
       "3  Behavior Management, Check-in, Educational/Voc...   \n",
       "4  Behavior Management, Check-in, Educational/Voc...   \n",
       "\n",
       "                                            COMMENTS  \\\n",
       "0  CW spoke to Angel today and explained that CW ...   \n",
       "1  CW spoke to clinician Katlyn today who reports...   \n",
       "2  CW spoke to Laura today and asked how Angel wa...   \n",
       "3  CW met with Angel and Laura today for Angel's ...   \n",
       "4  CW spoke to Angel today and he reports he is a...   \n",
       "\n",
       "                                       COMMENTS_CLOB  ... STAFF_WHO_PH_OTH  \\\n",
       "0  CW spoke to Angel today and explained that CW ...  ...              NaN   \n",
       "1  CW spoke to clinician Katlyn today who reports...  ...              NaN   \n",
       "2  CW spoke to Laura today and asked how Angel wa...  ...              NaN   \n",
       "3  CW met with Angel and Laura today for Angel's ...  ...              NaN   \n",
       "4  CW spoke to Angel today and he reports he is a...  ...              NaN   \n",
       "\n",
       "  STAFF_WHO_PH_EXT STAFF_WHO_PH_EXT_OTH STAFF_WHO_PH_INT STAFF_WHO_PH_INT_OTH  \\\n",
       "0              NaN                  NaN              NaN                  NaN   \n",
       "1              NaN                  NaN              NaN                  NaN   \n",
       "2              NaN                  NaN              NaN                  NaN   \n",
       "3              NaN                  NaN              NaN                  NaN   \n",
       "4              NaN                  NaN              NaN                  NaN   \n",
       "\n",
       "  STAFF_NOTES STAFF_REC                                       CMN_COMMENTS  \\\n",
       "0         NaN       NaN  CW spoke to Angel today and explained that CW ...   \n",
       "1         NaN       NaN  CW spoke to clinician Katlyn today who reports...   \n",
       "2         NaN       NaN  CW spoke to Laura today and asked how Angel wa...   \n",
       "3         NaN       NaN  CW met with Angel and Laura today for Angel's ...   \n",
       "4         NaN       NaN  CW spoke to Angel today and he reports he is a...   \n",
       "\n",
       "  CMN_STAFFING_TYPE                                              TOKEN  \n",
       "0               NaN  [cw, spoke, angel, today, explained, cw, ran, ...  \n",
       "1               NaN  [cw, spoke, clinician, katlyn, today, reports,...  \n",
       "2               NaN  [cw, spoke, laura, today, asked, angel, since,...  \n",
       "3               NaN  [cw, met, angel, laura, today, angel, 's, 90, ...  \n",
       "4               NaN  [cw, spoke, angel, today, reports, almost, don...  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW spoke to Angel today and explained that CW ran is time time assignment concurrent with his original time assignment but will discharge 8/19 unless he can do really really well and CW will ask for an early discharge. Angel was OK with that and reports he will try his hardest.\n",
      "['cw', 'spoke', 'angel', 'today', 'explained', 'cw', 'ran', 'time', 'time', 'assignment', 'concurrent', 'original', 'time', 'assignment', 'discharge', '8/19', 'unless', 'really', 'really', 'well', 'cw', 'ask', 'early', 'discharge', 'angel', 'ok', 'reports', 'try', 'hardest']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"COMMENTS\"][0])\n",
    "print(df['TOKEN'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_token=[]\n",
    "for x in df['TOKEN']:\n",
    "    all_token.append(x)\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "nlp = spacy.load('en',disable=['parser', 'ner'])\n",
    "lemma=lemmatization(all_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "for x in lemma:\n",
    "    for y in x:\n",
    "        final.append(y)\n",
    "count=Counter(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('go', 89018), ('client', 88647), ('report', 83318), ('call', 80083), ('home', 73384), ('would', 61497), ('meet', 61052), ('mother', 58560), ('school', 57957), ('work', 53329), ('writer', 52126), ('speak', 51266), ('today', 49841), ('state', 49482), ('program', 49456), ('check', 45381), ('also', 44943), ('time', 42909), ('ask', 39610), ('well', 38549), ('youth', 37509), ('discuss', 36863), ('meeting', 36665), ('say', 36494), ('get', 35721), ('take', 34172), ('need', 32846), ('come', 32244), ('visit', 31501), ('inform', 31049), ('week', 30991), ('tell', 30094), ('attend', 28678), ('issue', 28168), ('day', 27704), ('know', 26734), ('see', 26471), ('mom', 26430), ('make', 26418), ('contact', 26204), ('back', 26204), ('want', 25886), ('leave', 25256), ('office', 25154), ('schedule', 24342), ('phone', 24111), ('job', 24076), ('pick', 24021), ('could', 23911), ('family', 23270), ('give', 23124), ('receive', 21988), ('pass', 21783), ('next', 20827), ('continue', 20607), ('plan', 20592), ('transport', 20466), ('bring', 20241), ('let', 20070), ('return', 19563), ('follow', 19198), ('set', 19145), ('able', 19016), ('regard', 18830), ('case', 18586), ('message', 18348), ('tomorrow', 18040), ('good', 17883), ('community', 17043), ('send', 16638), ('talk', 15952), ('caseworker', 15354), ('staff', 15317), ('court', 15255), ('date', 14985), ('sign', 14805), ('still', 14721), ('due', 13935), ('complete', 13729), ('look', 13673), ('concern', 13435), ('request', 13301), ('place', 13222), ('new', 13032), ('email', 12919), ('start', 12892), ('update', 12683), ('last', 12655), ('student', 12487), ('class', 12432), ('text', 12308), ('try', 12088), ('thing', 12073), ('appointment', 12065), ('present', 11875), ('parent', 11730), ('information', 11671), ('service', 11633), ('feel', 11405), ('explain', 11301), ('treatment', 11228), ('agree', 10909), ('attempt', 10588), ('stay', 10496), ('help', 10283), ('test', 10252), ('move', 10207), ('behavior', 10076), ('hiset', 10060), ('reach', 10045), ('morning', 9945), ('weekend', 9802), ('house', 9675), ('remind', 9373), ('may', 9178), ('placement', 8980), ('advise', 8935), ('team', 8922), ('charge', 8841), ('find', 8782), ('participate', 8507), ('provide', 8478), ('later', 8459), ('hear', 8305), ('staffing', 8288), ('worker', 8250), ('answer', 8245), ('stop', 8233), ('support', 8177), ('drop', 8144), ('apartment', 8100), ('discharge', 8024), ('unit', 8004), ('night', 7778), ('pm', 7683), ('grandmother', 7571), ('review', 7563), ('number', 7555), ('-', 7546), ('curfew', 7490), ('address', 7420), ('friend', 7410), ('texte', 7288), ('use', 7190), ('clinical', 7108), ('employment', 7029), ('therapy', 6915), ('hold', 6907), ('confirm', 6902), ('seem', 6793), ('month', 6655), ('ecc', 6618), ('drive', 6580), ('informed', 6569), ('hour', 6560), ('yesterday', 6490), ('foster', 6414), ('interview', 6403), ('process', 6389), ('keep', 6306), ('forward', 6208), ('father', 6207), ('conduct', 6196), ('goal', 6188), ('cw', 6184), ('wait', 6158), ('high', 6149), ('left', 6124), ('card', 6123), ('incident', 6119), ('show', 6104), ('application', 5963), ('release', 5957), ('put', 5923), ('live', 5920), ('question', 5863), ('early', 5827), ('search', 5819), ('like', 5771), ('rrt', 5741), ('appear', 5717), ('paperwork', 5701), ('dys', 5640), ('respond', 5540), ('express', 5537), ('care', 5508), ('group', 5492), ('remain', 5484), ('director', 5480), ('long', 5480), ('afternoon', 5401), ('area', 5382), ('obtain', 5381), ('begin', 5373), ('clothing', 5365), ('arrive', 5329), ('end', 5321), ('change', 5300), ('progress', 5286), ('notify', 5280)]\n"
     ]
    }
   ],
   "source": [
    "print(count.most_common(200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
